{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Recommender Systems\n",
    "[Yukun Liu](mailto:yukun.liu@telecom-paris.fr), [Xiuhan Su](mailto:xiuhan.su@telecom-paris.fr)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 1. Presentation of the model\n",
    "> #### Question 1.1 \n",
    ">Download the file and check size of R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from movielens_utils import *\n",
    "from scipy.optimize import check_grad\n",
    "from scipy.sparse.linalg import svds\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gamma(x, gamma0, a, bcoef, R, mask, rho, Q=None):\n",
    "    \"\"\"\n",
    "    Function based on Talyor based line search to find the next step in optimization\n",
    "    x : current position. F-by-N matrix when Q is not None; Vector of size (U+I)*F when Q is None\n",
    "    gamma0 : scalar, current step size\n",
    "    a, bcoef : scalar, parameters for line search. gamma' = ba^l\n",
    "    Q : None when P is the only variable; Otherwise it's a U-by-F matrix\n",
    "    \"\"\"\n",
    "    b = bcoef * gamma0\n",
    "    \n",
    "    for l in range(0,100):\n",
    "        \n",
    "        gamma = b * a**l     \n",
    "        \n",
    "        if Q is None: \n",
    "            # Take both P,Q as variable\n",
    "            val, x_grad = total_objective_vectorized(x, R, mask, rho)\n",
    "            \n",
    "            x_new = x - gamma * x_grad\n",
    "            val_new, x_new_grad = total_objective_vectorized(x_new, R, mask, rho)            \n",
    "            \n",
    "        else:\n",
    "            # Q fixed, find next step and gradient\n",
    "            val, x_grad = objective(x, Q, R, mask, rho)\n",
    "            \n",
    "            x_new = x - gamma * x_grad            \n",
    "            val_new, x_new_grad = objective(x_new, Q, R, mask, rho)\n",
    "                    \n",
    "        measure = val - val_new - 1/2 * gamma * np.linalg.norm(x_grad)**2\n",
    "\n",
    "        if measure > 0:\n",
    "            break\n",
    "\n",
    "    return x_new, x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = None\n",
    "Q0 is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -2.24999596,  -0.47669652,  -7.53996919, ...,  11.94231691,\n",
       "          2.55386113, -21.89016068]),\n",
       " array([ -316540.24655081,   -37851.26524256,  -198237.52116525, ...,\n",
       "          797737.87242343,   115747.11859261, -5367844.43805392]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_gamma(PQvec_gradini, 0.5, 0.5, 2, R, mask, rho) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.29214220e+00,  2.59631066e-01,  3.91331221e+00, ...,\n",
       "         -7.65675269e-02,  6.21193266e-03,  1.40539885e-01],\n",
       "        [-1.84964226e+00, -6.84220063e+00, -1.27477512e+00, ...,\n",
       "          5.84546972e-02, -4.98278481e-02, -2.86667351e-02],\n",
       "        [-1.07142640e+01, -8.61895266e-01, -3.52028132e+00, ...,\n",
       "         -5.51924247e-02,  1.29609820e-02,  2.50202532e-02],\n",
       "        [ 3.07667053e+01,  1.12812787e+01,  6.39203035e+00, ...,\n",
       "          9.75168842e-03,  1.06289667e-01,  1.01724465e-01]]),\n",
       " array([[-2.55187226e+00, -5.12794303e-01, -7.72902323e+00, ...,\n",
       "          1.51228532e-01, -1.22691968e-02, -2.77580346e-01],\n",
       "        [ 3.66533699e+00,  1.35593934e+01,  2.52626923e+00, ...,\n",
       "         -1.15843346e-01,  9.87470232e-02,  5.68106700e-02],\n",
       "        [ 2.12540485e+01,  1.70974042e+00,  6.98332630e+00, ...,\n",
       "          1.09488580e-01, -2.57115014e-02, -4.96342027e-02],\n",
       "        [-6.13415087e+01, -2.24921984e+01, -1.27442031e+01, ...,\n",
       "         -1.94426274e-02, -2.11917222e-01, -2.02815223e-01]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_gamma(P0, 0.5, 0.5, 2, R, mask, rho, Q0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of R is (943, 1682)\n",
      "The mini size of R is (100, 200)\n"
     ]
    }
   ],
   "source": [
    "# filename = \"D:/Telecom 1e anne/Telecom Period 2/SD-TSIA211/TP/ml-100k/u.data\"\n",
    "filename = os.getcwd() + '\\\\ml-100k\\\\u.data'\n",
    "[R, mask] = load_movielens(filename, minidata=False)\n",
    "[mini_R, mini_mask] = load_movielens(filename, minidata=True)\n",
    "\n",
    "print('The size of R is {}'.format(R.shape))\n",
    "print('The mini size of R is {}'.format(mini_R.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has an original size $(943,1682)$, and it reduces to $(100,200)$ when option **minidata** is on. **minidata** is used to reduce the matrix size R, which can process the iteration speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Question 1.2\n",
    ">How many user and flms are there in the database ? What is the total number of grades ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 943 users and 1682 films in the database, and the total number of grades is 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2. Find $P$ when $Q^0$ is fixed\n",
    "> #### Question 2.1\n",
    ">Calculate the gradient of function $g$. We will admit that this gradient is Lipschitz continuous with constant $L_0 = \\rho+||Q^0)^TQ^0||_F$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the context, we know\n",
    "$$g(P)=\\frac{1}{2}\\mathop{\\Sigma}_{u\\in U, i \\in I}(R_{u,i}-(\\mathbb{1}_K)_{u,i}\\mathop{\\Sigma}_{f\\in F}Q_{u,f}P_{f,i})^2+\\frac{\\rho}{2}\\mathop{\\Sigma}_{u\\in U, f \\in F}Q_{u,f}^2+\\frac{\\rho}{2}\\mathop{\\Sigma}_{i\\in I, f \\in F}P_{f,i}^2$$\n",
    "\n",
    "Furthermore its gradient $\\triangledown g=\\frac{\\partial g(P)}{\\partial P}$ is a $F$ by $I$ matrix. While the (m,n) element of gradient $\\triangledown g$ can be denoted by\n",
    "\n",
    "$$\\begin{aligned}\n",
    "[\\triangledown g][\\triangledown g]_{m,n}&=\\frac{\\partial g(P)}{\\partial P_{m,n}}\\\\\n",
    "&=\\mathop{\\Sigma}_{u\\in U}Q^0_{u,m}(\\mathbb{1}_K)_{u,n}((\\mathbb{1}_K)_{u,n}\\mathop{\\Sigma}_{f\\in F}Q^0_{u,f}P_{f,n}-R_{u,n})+\\rho P_{m,n}\\\\\n",
    "% &=\\mathop{\\Sigma}_{u\\in U}(Q^0)^T_{m,u}(\\mathbb{1}_K)_{u,n}(\\mathop{\\Sigma}_{f\\in F}Q^0_{u,f}P_{f,n}-R_{u,n})+\\rho P_{m,n}\\\\\n",
    "&=\\mathop{\\Sigma}_{u\\in U}(Q^0)^T_{m,u}(\\mathbb{1}_K)_{u,n}(Q^0P)_{u,n}-(Q^0)^T_{m,:}R_{:,n}+\\rho P_{m,n}\\\\\n",
    "&=\\mathop{\\Sigma}_{u\\in U}(Q^0)^T_{m,u}(\\mathbb{1}_K\\circ Q^0P)_{u,n}-(Q^0)^T_{m,:}R_{:,n}+\\rho P_{m,n}\\\\\n",
    "% &=\\mathop{\\Sigma}_{f\\in F}\\mathop{\\Sigma}_{u\\in U}(Q^0)^T_{m,u}Q^0_{u,f}(\\mathbb{1}_K)_{u,n}P_{f,n}-(Q^0_{m,:})^TR_{:,n}+\\rho P_{m,n}\\\\\n",
    "% &=\\mathop{\\Sigma}_{f\\in F}[(Q^0)^TQ^0]_{m,f}P_{f,n}(\\mathbb{1}_K)_{u,n}-(Q^0_{m,:})^TR_{:,n}+\\rho P_{m,n}\\\\\n",
    "% &=[(Q^0)^T]_{m,:}(\\mathbb{1}_K\\circ Q^0P)_{:,n}-(Q^0)^T_{m,:}R_{:,n}+\\rho P_{m,n}\\\\\n",
    "&= [(Q^0)^T(\\mathbb{1}_K\\circ Q^0P)]_{m,n}-[(Q^0)^TR]_{m,n}+\\rho P_{m,n}\n",
    "\\end{aligned}$$\n",
    "\n",
    "And the gradient can be formulated as\n",
    "$$\\begin{aligned}\n",
    "\\triangledown g(P) &= (Q^0)^T(\\mathbb{1}_K\\circ Q^0P)-(Q^0)^TR+\\rho P\\\\\n",
    "&= (Q^0)^T(\\mathbb{1}_K\\circ Q^0P-R)+\\rho P\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Question 2.2\n",
    ">The function objective provided in the file _movielens utils.py_ computes g(P). Complete\n",
    "this function so that it also computes $\\triangledown g(P)$. You may check your calculations with the\n",
    "function _scipy.optimize.check grad_ (you may need _numpy.reshape_ and _numpy.ravel_\n",
    "because check grad does not accept matrix variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(P):\n",
    "    '''\n",
    "    cost function w.r.t Q\n",
    "    P : column vector of size(1, F*C)\n",
    "    mask, R taken as given\n",
    "    '''\n",
    "    if P.size == 6728:\n",
    "        P = P.reshape(4, 1682)\n",
    "        \n",
    "    tmp = (R - Q0.dot(P)) * mask\n",
    "    value = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    return value\n",
    "\n",
    "def grad(P, ravel=True):\n",
    "    '''\n",
    "    gradient function w.r.t Q\n",
    "    P : column vector of size(1, F*C)\n",
    "    ravel : True when P is ravelled to a column vector\n",
    "    '''\n",
    "    \n",
    "    if ravel:\n",
    "        P = P.reshape(4, 1682)\n",
    "        tmp = (R - Q0.dot(P)) * mask \n",
    "        grad_P = np.ravel(Q0.T.dot(-tmp) + rho * P)\n",
    "\n",
    "    else:\n",
    "        tmp = (R - Q0.dot(P)) * mask \n",
    "        grad_P = Q0.T.dot(-tmp) + rho * P            \n",
    "\n",
    "    return  grad_P   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f146bdf93fe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_P\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The gradient error is {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'func' is not defined"
     ]
    }
   ],
   "source": [
    "rho = 0.5\n",
    "\n",
    "Q0,s,P0 = svds(R, k=4)\n",
    "\n",
    "[val, grad_P] = objective(P0, Q0, R, mask, rho)\n",
    "\n",
    "err = check_grad(func, grad, np.ravel(P0))\n",
    "\n",
    "print('The gradient error is {}'.format(err))\n",
    "print('The norm is {}'.format( np.linalg.norm(grad_P) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the norm of gradient, the error is relatively small. Then a conclusion can be drawn that our function of gradient is derived in the right way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Question 2.3 \n",
    ">Code a function `gradient(g, P0, gamma, epsilon)` that minimizes a function g using the gradient method with a constant step size, $\\gamma$, starting from the initial point $P^0$ and with stopping criterion $||\\triangledown g(P_k)||_F\\le \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Question 2.4\n",
    "Run the function coded in the previous question in order to minimize g up to the precision $\\epsilon = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the gradient is Lipschitz continuous with constant $L_0 = \\rho+||Q^0)^TQ^0||_F$, the constant step size will be set as $$\\gamma = \\frac{2}{L_0}$$\n",
    "\n",
    "The sequence of points $(P_k)_{k \\in \\mathbb{N}}$ in $\\mathbb{R}^{F\\times I}$ will be defined by\n",
    "$$P_{k+1}=P_k-\\gamma \\triangledown g(P_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setting\n",
    "L0 = rho + np.linalg.norm( Q0.T.dot(Q0) )\n",
    "Q0,s,P0 = svds(R, k=4)\n",
    "Gamma  = 2 / L0\n",
    "G0 = grad(P0, ravel=False)\n",
    "Epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision is 0.5831508360169965\n",
      "The optimality is achieved in 10 steps\n"
     ]
    }
   ],
   "source": [
    "# constant step \n",
    "gout = gradient(P0, Gamma, Epsilon, Q=Q0)\n",
    "\n",
    "print('The precision is {}'.format(np.linalg.norm(gout[0])))\n",
    "print('The optimality is achieved in {} steps'.format(gout[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Question 2.5\n",
    "Add a line search to your gradient method, so that you do not rely on the Lipschitz constant of the gradient any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Talyor-based line search, we have\n",
    "\n",
    "$$g(P^+(\\gamma_k))\\le g(P_k)+\\langle\\triangledown g(P_k), P^+(\\gamma_k)-P_k\\rangle+\\frac{1}{2\\gamma_k}\\|P_k-P^+(\\gamma_k)\\|^2,k\\in\\{1,\\cdots,N\\}$$\n",
    "\n",
    "where $P^+(\\gamma_k)=P_k-\\gamma_k\\triangledown g(P_k)$ and $\\gamma_k = ba^l,b>0, a\\in(0,1)$, $l$ is bounded by the criterion that $L'=\\frac{1}{\\gamma_k}\\ge L$.\n",
    "\n",
    "Since $P^+(\\gamma_k)-P_k=-\\gamma_k\\triangledown g(P_k)$, the inequality can be formulated as \n",
    "\n",
    "$$ g(P_k)-g(P^+(\\gamma_k))-\\frac{\\gamma_k}{2}\\|\\triangledown g(P_k)\\|^2\\ge 0$$ $l$ is the smallest integer makes the inequality true. In the implementation, we chose the classical parameter: $a=0.5,b=2\\gamma_k$\n",
    "\n",
    "<!-- Let's set $$\\gamma_k = ba^l,k\\in\\{1,\\cdots,N\\}$$ where $a=0.5, b=2\\gamma_{k-1},l=\\lfloor \\frac{\\log(ba^{-1}L_0)}{\\log(a^{-1})}\\rfloor, \\gamma_0=\\frac{2}{L_0}$ to ensure the chosing step won't break the Lipschitz continuity.\n",
    "\n",
    "Since $L_0 = \\rho+||Q^0)^TQ^0||_F=2.5, \\gamma_0=\\frac{2}{L_0}=0.8,$ $l$ is chosen to be $1$ in this case. Besides, for those cases $L_0$ is unknown, $l=1$ will always be the least choice which indicates constant step size.\n",
    "Then \n",
    "$$P^+(\\gamma_k)=P_k-\\gamma_k\\triangledown g(P_k)$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision is 0.2548694987212456\n",
      "The optimality is achieved in 8 steps\n"
     ]
    }
   ],
   "source": [
    "# linsearch\n",
    "gout_lsch = gradient(P0, Gamma, Epsilon, a=0.5, bcoef=2, Q=Q0)\n",
    "\n",
    "print('The precision is {}'.format(np.linalg.norm(gout_lsch[0])))\n",
    "print('The optimality is achieved in {} steps'.format(gout_lsch[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Resolution of the full problem\n",
    "> #### Question 3.1 \n",
    "Let f be the function defined by $f(P,Q) = \\frac{1}{2}\\|\\mathbb{1}_K \\circ(R-QP)\\|^2_F+\\frac{\\rho}{2}\\|Q\\|^2_F+\\frac{\\rho}{2}\\|P\\|^2_F$. \n",
    ">\n",
    ">By remarking that f is a polynomial of degree 4, show that its gradient is not Lipschitz\n",
    "continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $f$ is expressed as\n",
    "$$f(P,Q)=\\frac{1}{2}\\mathop{\\Sigma}_{u\\in U, i \\in I}(R^2_{u,i}-2(\\mathbb{1}_K)_{u,i}R_{u,i}\\mathop{\\Sigma}_{f\\in F}Q_{u,f}P_{f,i}+\\mathop{\\Sigma}_{a,b\\in F}Q_{u,a}P_{a,i}Q_{u,b}P_{b,i})+\\frac{\\rho}{2}\\mathop{\\Sigma}_{u\\in U, f \\in F}Q_{u,f}^2+\\frac{\\rho}{2}\\mathop{\\Sigma}_{i\\in I, f \\in F}P_{f,i}^2$$\n",
    "\n",
    "And we can tell the mysterious term $\\mathop{\\Sigma}_{a,b\\in F}Q_{u,a}P_{a,i}Q_{u,b}P_{b,i}$ is with order of 4. As a result, $f$ is not Lipschitz continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Question 3.2\n",
    "Solve Problem (1) by the gradient method with line search until reaching the precision\n",
    "$\\|\\triangledown f(P_k,Q_k)\\|_F \\le\\epsilon$ with $\\epsilon = 100$. How do you interpret what the algorithm returns ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of function $f$ w.r.t $Q$ can be derived in a similar way as Prob.(2.1), then we have\n",
    "\n",
    "$$\\frac{\\partial f(P,Q)}{\\partial P}= Q^T(\\mathbb{1}_K\\circ QP-R)+\\rho P$$\n",
    "$$\\frac{\\partial f(P,Q)}{\\partial Q}= (\\mathbb{1}_K\\circ QP-R)P^T+\\rho Q$$\n",
    "while $\\frac{\\partial f(P,Q)}{\\partial P}\\in\\mathbb{R}^{F\\times I},\\frac{\\partial f(P,Q)}{\\partial Q}\\in\\mathbb{R}^{U\\times F}$.\n",
    "And the overall gradient is \n",
    "$$\\triangledown f(P,Q)=\\\n",
    "\\begin{bmatrix}\\frac{\\partial f(P,Q)}{\\partial P}\\\\ \\frac{\\partial f^T(P,Q)}{\\partial Q}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Similary, to implement the Taylor based line search, we'll find the step $\\gamma_k=ba^l$ s.t.\n",
    "$$ f(P_k,Q_k)-f(P^+(\\gamma_k),Q^+(\\gamma_k))-\\frac{\\gamma_k}{2}\\|\\triangledown f(P_k,Q_k)\\|^2\\ge 0$$ $l$ is the smallest integer makes the inequality true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val0, grad_P0, grad_Q0 = total_objective(P0, Q0, R, mask, rho)\n",
    "\n",
    "PQvec_ini = np.concatenate([grad_P0.ravel(), grad_Q0.ravel()])\n",
    "val0, PQvec_1 = total_objective_vectorized(PQvec_ini, R, mask, rho)\n",
    "val1, PQvec_2 = total_objective_vectorized(PQvec_1, R, mask, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 100\n",
    "PQvec_gradini = np.concatenate([grad_P0.ravel(), grad_Q0.ravel()])\n",
    "gamma_test = 0.5\n",
    "# find_gamma(PQvec_gradini, gamma_test, 0.5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gamma(PQvec, gamma0, a, bcoef):\n",
    "    \n",
    "    b = bcoef * gamma0\n",
    "    \n",
    "    for l in range(0,100):\n",
    "        \n",
    "        gamma = b * a**l\n",
    "        val0, PQvec_grad = total_objective_vectorized(PQvec, R, mask, rho)\n",
    "        PQvec_new = PQvec - gamma * PQvec_grad\n",
    "        \n",
    "        val1, PQvec_grad1 = total_objective_vectorized(PQvec_new, R, mask, rho)\n",
    "        \n",
    "        measure = val0 - val1 - 1/2 * gamma * np.linalg.norm(PQvec_grad)**2\n",
    "\n",
    "        if measure > 0:\n",
    "#             print(l)\n",
    "            break\n",
    "\n",
    "    return gamma, PQvec_new, PQvec_grad\n",
    "\n",
    "def gradient_all(P, Q = None, gamma0, epsilon, a = None, bcoef = None):\n",
    "    \"\"\"\n",
    "    minimizes a function g using the gradient method\n",
    "    P : initial point\n",
    "    gamma : constant step size\n",
    "    epsilon : exit criterion\n",
    "    lsch : True when applying Taylor based line search\n",
    "    \"\"\"\n",
    "    \n",
    "    counter = 0 # step size\n",
    "    \n",
    "    PQvec = np.concatenate([P.ravel(), Q.ravel()])\n",
    "    \n",
    "    val0, grad_P0, grad_Q0 = total_objective(P, Q, R, mask, rho)\n",
    "    \n",
    "    PQvec_grad = np.concatenate([grad_P0.ravel(), grad_Q0.ravel()])\n",
    "    \n",
    "    while np.linalg.norm(PQvec_grad) > epsilon :\n",
    "        counter += 1            \n",
    "\n",
    "        if a != None and bcoef != None:\n",
    "            \"\"\"\n",
    "            line search method calculating step size\n",
    "            \"\"\"\n",
    "            gamma0, PQvec, PQvec_grad = find_gamma(PQvec, gamma0, a, bcoef)  \n",
    "              \n",
    "    return np.linalg.norm(PQvec_grad), counter, PQvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(P, gamma, epsilon, a = None, bcoef = None, Q = None):\n",
    "    \"\"\"\n",
    "    minimizes a function g using the gradient method\n",
    "    P : initial point\n",
    "    gamma : constant step size\n",
    "    epsilon : exit criterion\n",
    "    lsch : True when applying Taylor based line search\n",
    "    \"\"\"\n",
    "    \n",
    "    counter = 0 # step size\n",
    "#     g = grad(P, ravel=False)   \n",
    "    g = epsilon+1\n",
    "    while np.linalg.norm(g) > epsilon :\n",
    "        counter += 1            \n",
    "\n",
    "        if a != None and bcoef != None:\n",
    "            # line search case              \n",
    "            P, g = find_gamma(P, gamma, a, bcoef, R, mask, rho)\n",
    "              \n",
    "        else:\n",
    "            # constant step size gamma\n",
    "            P = P - gamma * g            \n",
    "            val, g = objective(P, Q0, R, mask, rho)\n",
    "\n",
    "    return g, counter\n",
    "\n",
    "def find_step(g, P, gamma0, a, bcoef):\n",
    "    b = bcoef * gamma0\n",
    "    for l in range(0,100):\n",
    "        \n",
    "        gamma = b * a**l\n",
    "        measure = func(P) - func(P - gamma*g) - 1/2 * gamma * np.linalg.norm(g)**2\n",
    "\n",
    "        if measure > 0:\n",
    "            break\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0.5\n",
    "PQvec = np.concatenate([P0.ravel(), Q0.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 100\n",
    "grad, steps = gradient(PQvec, gamma_test, epsilon,  a = 0.5, bcoef = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96.6190993497376, 88)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(grad), steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = R.shape[1]\n",
    "n_users = R.shape[0]\n",
    "F = PQvec.shape[0] // (n_items + n_users)\n",
    "\n",
    "Pvec = PQvec[0:n_items*F]\n",
    "Qvec = PQvec[n_items*F:]\n",
    "\n",
    "P = np.reshape(Pvec, (F, n_items))\n",
    "Q = np.reshape(Qvec, (n_users, F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = Q.dot(P)\n",
    "\n",
    "df = pd.DataFrame(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =  df[300][df.iloc[300] > 4].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned $Q$ and $P$ indicate the matrixes make the term $QP$ **most close** to our observation $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Question 3.3\n",
    "What film would you recommend to user 300 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R[299][R[299] > 4]\n",
    "R[299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "user = 299\n",
    "thres = 4 # the rating no less than thres will be recommended\n",
    "\n",
    "rec_index =  df[user][df.iloc[user] > 4.5].index.tolist()\n",
    "print(len(rec_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For User 300, we will recommend the film in index\n",
    "$[99, 256, 287, 293, 299, 327]$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
